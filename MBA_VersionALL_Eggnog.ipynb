{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',95)\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('precision',4)\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the pickled file\n",
    "f = open('df5.pkl', 'rb')\n",
    "df5 = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change item_description to item_name\n",
    "df5.rename(columns={'item_description' : 'item_name'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of different store types\n",
    "df5.store_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_item_names = df5.item_name.value_counts()\n",
    "all_item_names.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Basket Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for top 500 item names that accounted for higher volume sales\n",
    "top_500 = df5.groupby(['item_name']).agg({'volume_sold_liters': 'sum'}).sort_values(\n",
    "    by = 'volume_sold_liters', ascending= False).reset_index()[0:500]['item_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_500[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe using top_50 item name list for MBA \n",
    "df_top_500 = df5.loc[df5['item_name'].isin(top_500)]\n",
    "df_top_500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the df_top_50\n",
    "df_top_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure Egg Nog in list\n",
    "[s for s in top_500 if s.lower().find('egg nog')>=0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this one item above the only egg nog?\n",
    "egg_nog_names = [s for s in all_item_names.index.values if s.lower().find('egg nog')>=0 ]\n",
    "egg_nog_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basket(df, store_filter=None, month=None, date_grouping_freq='M', item_filter=None):\n",
    "  '''\n",
    "  Make the basket of items bought together and filter by \n",
    "      store_filter: 'supermarket', 'retail store', 'convenience store', 'big box', 'drugstore'\n",
    "      month: 1-12 for month;  January==1, December==12\n",
    "      date_grouping_freq: 'M' for group by month, 'W' by week\n",
    "      item_filter: filter by item_name containing the string here. \n",
    "  '''\n",
    "  if store_filter:\n",
    "    df = df.loc[ df['store_type']==store_filter ]\n",
    "  if month:\n",
    "    df = df.loc[ df['date'].dt.month == month ]\n",
    "  if item_filter:\n",
    "    df = df.loc[ df['item_name'].str.contains(item_filter) ]\n",
    "  basket = (df.groupby(\n",
    "      [pd.Grouper(key='date',freq=date_grouping_freq),\n",
    "       'store_number','item_name']\n",
    "       )['item_name'].size().unstack().\\\n",
    "       reset_index().fillna(0).set_index(['date','store_number']))\n",
    "  def encode_units(x):\n",
    "      if x <= 0:\n",
    "          return 0\n",
    "      if x >= 1:\n",
    "          return 1\n",
    "  basket = basket.applymap(encode_units)\n",
    "  return basket, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_most_freq_items(df, label):\n",
    "  # Most frequent items bar plot\n",
    "  s = df['item_name'].value_counts().head(20)\n",
    "  num_items = len(s)\n",
    "  color = plt.cm.inferno(np.linspace(0,1,num_items))\n",
    "  plt.rcParams['figure.figsize'] = (10,6)\n",
    "  s.plot.bar(color = color)\n",
    "  plt.title(f'Top {num_items} Most Frequent Items in {label}')\n",
    "  plt.ylabel('Counts')\n",
    "  plt.xlabel('Items')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules = {} # dict to store rules from various scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL Stores\n",
    "print('\\n\\n' + '='*80 + f'\\n========== ALL STORES ==========\\n' + '='*80 + '\\n')\n",
    "basket, df_filtered = make_basket(df_top_500)\n",
    "plot_most_freq_items(df_filtered, label='ALL_STORES')\n",
    "frequent_itemssets = apriori(basket,min_support=0.1,max_len=2,use_colnames=True )\n",
    "# Creates association rules based on if-then frequency\n",
    "rules = association_rules(frequent_itemssets,metric='lift')\n",
    "\n",
    "all_rules['all_stores'] = rules\n",
    "\n",
    "# Prune rules\n",
    "#rules = rules[ (rules['confidence'] >= .90) & (rules['support'] >= 0.55) ]\n",
    "\n",
    "print('\\nTop 20 Rules sorted by support') \n",
    "print( rules.sort_values('support',ascending = False).head(20) )\n",
    "\n",
    "print('\\nTop 20 Rules sorted by confidence') \n",
    "print( rules.sort_values('confidence',ascending = False).head(20) )\n",
    "\n",
    "print('\\nTop 20 Rules sorted by lift') \n",
    "print( rules.sort_values('lift',ascending = False).head(20) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MBA for each store type\n",
    "store_types = ['supermarket', 'retail store', 'convenience store', 'big box', 'drugstore']\n",
    "\n",
    "for s in store_types:\n",
    "  print('\\n\\n' + '='*80 + f'\\n========== {s} ==========\\n' + '='*80 + '\\n')\n",
    "\n",
    "  basket, df_filtered = make_basket(df_top_500, store_filter=s)\n",
    "  plot_most_freq_items(df_filtered, label=s)\n",
    "  frequent_itemssets = apriori(basket,min_support=0.1,max_len=2,use_colnames=True )\n",
    "  # Creates association rules based on if-then frequency\n",
    "  rules = association_rules(frequent_itemssets,metric='lift')\n",
    "  all_rules[s] = rules\n",
    "\n",
    "  # Prune rules\n",
    "  #rules = rules[ (rules['confidence'] >= .90) & (rules['support'] >= 0.55) ]\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by support\\n') \n",
    "  print( rules.sort_values('support',ascending = False).head(20) )\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by confidence\\n') \n",
    "  print( rules.sort_values('confidence',ascending = False).head(20) )\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by lift\\n') \n",
    "  print( rules.sort_values('lift',ascending = False).head(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1, 13):\n",
    "  name = 'all_stores_month_' + f'{m:02}'\n",
    "  print('\\n\\n' + '='*80 + f'\\n========== {name} ==========\\n' + '='*80 + '\\n')\n",
    "  basket, df_filtered = make_basket(df_top_500, month=m)\n",
    "  plot_most_freq_items(df_filtered, label=name)\n",
    "  frequent_itemssets = apriori(basket,min_support=0.1,max_len=2,use_colnames=True )\n",
    "  # Creates association rules based on if-then frequency\n",
    "  rules = association_rules(frequent_itemssets,metric='lift')\n",
    "  all_rules[name] = rules\n",
    "\n",
    "  # Prune rules\n",
    "  #rules = rules[ (rules['confidence'] >= .90) & (rules['support'] >= 0.55) ]\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by support') \n",
    "  print( rules.sort_values('support',ascending = False).head(20) )\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by confidence') \n",
    "  print( rules.sort_values('confidence',ascending = False).head(20) )\n",
    "\n",
    "  print('\\nTop 20 Rules sorted by lift') \n",
    "  print( rules.sort_values('lift',ascending = False).head(20) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often is egg nog sold?  \n",
    "# as you see below, not very often compared to the > 15 million rows in the df_top_500\n",
    "print(f'Total number of rows in main df_top_500: {len(df_top_500):,}\\n')\n",
    "df_top_500[ df_top_500['item_name'].str.contains('egg nog') ]['item_name'].value_counts().plot(kind = 'bar', color= 'red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Egg Nog in December\n",
    "name = 'ALL STORES EGG NOG ONLY IN DECEMBERS ONLY'\n",
    "print('\\n\\n' + '='*80 + f'\\n========== {name} ==========\\n' + '='*80 + '\\n')\n",
    "basket, df_filtered = make_basket(df_top_500, month=12, item_filter=None)\n",
    "plot_most_freq_items(df_filtered, label=name)\n",
    "frequent_itemssets = apriori(basket,min_support=0.01,max_len=2,use_colnames=True )\n",
    "# Creates association rules based on if-then frequency\n",
    "rules = association_rules(frequent_itemssets,metric='lift')\n",
    "\n",
    "# Filter for only egg nog\n",
    "rules = rules[  rules['antecedents'].apply(lambda x: (str(x).find('egg nog'))>=0 ) ]\n",
    "\n",
    "all_rules[name] = rules\n",
    "\n",
    "print('\\nTop 20 Rules sorted by support') \n",
    "print( rules.sort_values('support',ascending = False))\n",
    "\n",
    "print('\\nTop 20 Rules sorted by confidence') \n",
    "print( rules.sort_values('confidence',ascending = False).head(20) )\n",
    "\n",
    "print('\\nTop 20 Rules sorted by lift') \n",
    "print( rules.sort_values('lift',ascending = False).head(20) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining all rules\n",
    "main_df = pd.DataFrame(columns=['antecedents', 'consequents'])\n",
    "for k, v in all_rules.items():\n",
    "  k = k.replace(\" \", \"_\")\n",
    "  temp = v.add_suffix(\" \" + k)\n",
    "  temp = temp.rename(columns={ 'antecedents '+k:'antecedents', 'consequents '+k:'consequents'})\n",
    "  main_df = pd.merge(main_df, temp, on=['antecedents', 'consequents'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = main_df.columns\n",
    "select_c = [c for c in columns if c.find('lift')==0 ]\n",
    "select_c = ['antecedents', 'consequents'] + select_c\n",
    "main_df[select_c].sort_values(by='lift all_stores', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wordcloud(df, store_filter=None, month=None):\n",
    "'''\n",
    "Make a WordCloud image and filter by\n",
    "store_filter: 'supermarket', 'retail store', 'convenience store',\n",
    "'big box', or 'drugstore'. None is all stores\n",
    "month: 1-12 for month; January==1, December==12\n",
    "'''\n",
    "if store_filter:\n",
    "df = df.loc[ df['store_type']==store_filter ]\n",
    "if month:\n",
    "df = df.loc[ df['date'].dt.month == month ]\n",
    "\n",
    "\n",
    "cloud_super = df['item_name'].value_counts().head(60).to_frame().reset_index()\n",
    "\n",
    "\n",
    "# create a dictionary with counts of frequency. For example:\n",
    "# { 'hawkeye vodka' : 140169,\n",
    "# 'black velvet'. : 131129,\n",
    "# 'five o'clock vodka': 97057,\n",
    "# ... }\n",
    "counter = dict( zip( cloud_super['index'], cloud_super['item_name'] ) )\n",
    "\n",
    "\n",
    "final_wordcloud = WordCloud(width = 800, height = 800,\n",
    "background_color ='black',\n",
    "min_font_size = 8).generate_from_frequencies(counter)\n",
    "\n",
    "\n",
    "# Plotting the WordCloud\n",
    "plt.figure(figsize = (10, 10), facecolor = None)\n",
    "plt.imshow(final_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "make_wordcloud(df_top_500,'supermarket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to visualize association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx  \n",
    "def draw_graph(rules, rules_to_show):\n",
    "  G1 = nx.DiGraph()   \n",
    "  color_map=[]\n",
    "  N = 50\n",
    "  colors = np.random.rand(N)    \n",
    "      \n",
    "  for i in range (rules_to_show):      \n",
    "    for a in rules.iloc[i]['antecedents']:               \n",
    "        G1.add_nodes_from([a])\n",
    "        consequent = list(rules.iloc[i]['consequents'])[0]\n",
    "        G1.add_edge(a, consequent, color=colors[i] , weight = 2)   \n",
    " \n",
    "  for node in G1:\n",
    "       found_a_string = False\n",
    "       if found_a_string:\n",
    "            color_map.append('yellow')\n",
    "       else:\n",
    "            color_map.append('green')       \n",
    "   \n",
    "  edges = G1.edges()\n",
    "  colors = [G1[u][v]['color'] for u,v in edges]\n",
    "  weights = [G1[u][v]['weight'] for u,v in edges]\n",
    " \n",
    "  pos = nx.spring_layout(G1, k=16, scale=1)\n",
    "  nx.draw( G1, pos, node_color = color_map, edge_color=colors, \n",
    "          width=weights, font_size=16, with_labels=False)            \n",
    "   \n",
    "  for p in pos:  # raise text positions\n",
    "           pos[p][1] += 0.07\n",
    "  nx.draw_networkx_labels(G1, pos)\n",
    "  plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Supermarkets\\n\\n\\n')\n",
    "rules_super = all_rules['supermarket']\n",
    "\n",
    "\n",
    "\n",
    "#r = rules_super[(rules_super['confidence'] >= .90) & (rules_super['support'] >= 0.55)].sort_values('lift',ascending = False).head(30)\n",
    "#print(rules_supermarket.columns)\n",
    "#r = r[ ['antecedents','consequents'] ].head(10)\n",
    "draw_graph( rules_super, 20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Retail Store\\n\\n\\n')\n",
    "rules_super = all_rules['retail store']\n",
    "draw_graph( rules_super, 20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Convenience Stores\\n\\n\\n')\n",
    "rules_super = all_rules['convenience store']\n",
    "draw_graph( rules_super, 20) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
